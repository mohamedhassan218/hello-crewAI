{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L7: Build a Crew to Tailor Job Applications\n",
    "\n",
    "In this lesson, you will built your first multi-agent system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libraries are already installed in the classroom. If you're running this notebook on your own machine, you can install the following:\n",
    "```Python\n",
    "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "height": 65
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import libraries, APIs and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_serper_api_key\n",
    "\n",
    "os.environ[\"SERPER_API_KEY\"] = get_serper_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"models/gemini-pro\", google_api_key=api_key)\n",
    "\n",
    "search_llm = GoogleGenerativeAI(model=\"models/gemini-pro\", google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crewAI Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "height": 201
   },
   "outputs": [
    {
     "ename": "SchemaError",
     "evalue": "Key 'llm' error:\nWrong keys 'additional_headers', 'cache', 'callback_manager', 'callbacks', 'client', 'client_options', 'credentials', 'custom_get_token_ids', 'google_api_key', 'max_output_tokens', 'max_retries', 'metadata', 'model', 'n', 'name', 'safety_settings', 'tags', 'temperature', 'timeout', 'top_k', 'top_p', 'transport', 'verbose' in {'name': None, 'cache': None, 'verbose': False, 'callbacks': None, 'tags': None, 'metadata': None, 'custom_get_token_ids': None, 'callback_manager': None, 'model': 'models/gemini-pro', 'google_api_key': SecretStr('**********'), 'credentials': None, 'temperature': 0.7, 'top_p': None, 'top_k': None, 'max_output_tokens': None, 'n': 1, 'max_retries': 6, 'timeout': None, 'client_options': None, 'transport': None, 'additional_headers': None, 'safety_settings': None, 'client': genai.GenerativeModel(\n    model_name='models/gemini-pro',\n    generation_config={},\n    safety_settings={},\n    tools=None,\n    system_instruction=None,\n)}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSchemaWrongKeyError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32md:\\Learning\\crewAI\\hello-crewAI\\.venv\\Lib\\site-packages\\schema.py:483\u001b[0m, in \u001b[0;36mSchema.validate\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m     nvalue \u001b[38;5;241m=\u001b[39m \u001b[43mSchema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43msvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_extra_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SchemaError \u001b[38;5;28;01mas\u001b[39;00m x:\n",
      "File \u001b[1;32md:\\Learning\\crewAI\\hello-crewAI\\.venv\\Lib\\site-packages\\schema.py:518\u001b[0m, in \u001b[0;36mSchema.validate\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    517\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepend_schema_name(message)\n\u001b[1;32m--> 518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SchemaWrongKeyError(message, e\u001b[38;5;241m.\u001b[39mformat(data) \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;66;03m# Apply default-having optionals that haven't been used:\u001b[39;00m\n",
      "\u001b[1;31mSchemaWrongKeyError\u001b[0m: Wrong keys 'additional_headers', 'cache', 'callback_manager', 'callbacks', 'client', 'client_options', 'credentials', 'custom_get_token_ids', 'google_api_key', 'max_output_tokens', 'max_retries', 'metadata', 'model', 'n', 'name', 'safety_settings', 'tags', 'temperature', 'timeout', 'top_k', 'top_p', 'transport', 'verbose' in {'name': None, 'cache': None, 'verbose': False, 'callbacks': None, 'tags': None, 'metadata': None, 'custom_get_token_ids': None, 'callback_manager': None, 'model': 'models/gemini-pro', 'google_api_key': SecretStr('**********'), 'credentials': None, 'temperature': 0.7, 'top_p': None, 'top_k': None, 'max_output_tokens': None, 'n': 1, 'max_retries': 6, 'timeout': None, 'client_options': None, 'transport': None, 'additional_headers': None, 'safety_settings': None, 'client': genai.GenerativeModel(\n    model_name='models/gemini-pro',\n    generation_config={},\n    safety_settings={},\n    tools=None,\n    system_instruction=None,\n)}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSchemaError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m scrape_tool \u001b[38;5;241m=\u001b[39m ScrapeWebsiteTool()\n\u001b[0;32m      5\u001b[0m read_resume \u001b[38;5;241m=\u001b[39m FileReadTool(file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fake_resume.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m semantic_search_resume \u001b[38;5;241m=\u001b[39m \u001b[43mMDXSearchTool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/gemini-pro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/embedding-001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mretrieval_document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Learning\\crewAI\\hello-crewAI\\.venv\\Lib\\site-packages\\crewai_tools\\tools\\mdx_seach_tool\\mdx_search_tool.py:32\u001b[0m, in \u001b[0;36mMDXSearchTool.__init__\u001b[1;34m(self, mdx, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mdx: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mdx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(mdx)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32md:\\Learning\\crewAI\\hello-crewAI\\.venv\\Lib\\site-packages\\crewai_tools\\tools\\rag\\rag_tool.py:47\u001b[0m, in \u001b[0;36mRagTool._set_default_adapter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01membedchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m App\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrewai_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedchain_adapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbedchainAdapter\n\u001b[1;32m---> 47\u001b[0m     app \u001b[38;5;241m=\u001b[39m \u001b[43mApp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;28;01melse\u001b[39;00m App()\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter \u001b[38;5;241m=\u001b[39m EmbedchainAdapter(\n\u001b[0;32m     49\u001b[0m         embedchain_app\u001b[38;5;241m=\u001b[39mapp, summarize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarize\n\u001b[0;32m     50\u001b[0m     )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Learning\\crewAI\\hello-crewAI\\.venv\\Lib\\site-packages\\embedchain\\app.py:363\u001b[0m, in \u001b[0;36mApp.from_config\u001b[1;34m(cls, config_path, config, auto_deploy, yaml_path)\u001b[0m\n\u001b[0;32m    360\u001b[0m     config_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# Validate the config\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[43mvalidate_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m app_config_data \u001b[38;5;241m=\u001b[39m config_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m    366\u001b[0m vector_db_config_data \u001b[38;5;241m=\u001b[39m config_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectordb\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n",
      "File \u001b[1;32md:\\Learning\\crewAI\\hello-crewAI\\.venv\\Lib\\site-packages\\embedchain\\utils\\misc.py:503\u001b[0m, in \u001b[0;36mvalidate_config\u001b[1;34m(config_data)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_config\u001b[39m(config_data):\n\u001b[0;32m    383\u001b[0m     schema \u001b[38;5;241m=\u001b[39m Schema(\n\u001b[0;32m    384\u001b[0m         {\n\u001b[0;32m    385\u001b[0m             Optional(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp\u001b[39m\u001b[38;5;124m\"\u001b[39m): {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    500\u001b[0m         }\n\u001b[0;32m    501\u001b[0m     )\n\u001b[1;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Learning\\crewAI\\hello-crewAI\\.venv\\Lib\\site-packages\\schema.py:489\u001b[0m, in \u001b[0;36mSchema.validate\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m nkey\n\u001b[0;32m    488\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepend_schema_name(k)\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SchemaError(\n\u001b[0;32m    490\u001b[0m         [message] \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39mautos,\n\u001b[0;32m    491\u001b[0m         [e\u001b[38;5;241m.\u001b[39mformat(data) \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    492\u001b[0m     )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m     new[nkey] \u001b[38;5;241m=\u001b[39m nvalue\n",
      "\u001b[1;31mSchemaError\u001b[0m: Key 'llm' error:\nWrong keys 'additional_headers', 'cache', 'callback_manager', 'callbacks', 'client', 'client_options', 'credentials', 'custom_get_token_ids', 'google_api_key', 'max_output_tokens', 'max_retries', 'metadata', 'model', 'n', 'name', 'safety_settings', 'tags', 'temperature', 'timeout', 'top_k', 'top_p', 'transport', 'verbose' in {'name': None, 'cache': None, 'verbose': False, 'callbacks': None, 'tags': None, 'metadata': None, 'custom_get_token_ids': None, 'callback_manager': None, 'model': 'models/gemini-pro', 'google_api_key': SecretStr('**********'), 'credentials': None, 'temperature': 0.7, 'top_p': None, 'top_k': None, 'max_output_tokens': None, 'n': 1, 'max_retries': 6, 'timeout': None, 'client_options': None, 'transport': None, 'additional_headers': None, 'safety_settings': None, 'client': genai.GenerativeModel(\n    model_name='models/gemini-pro',\n    generation_config={},\n    safety_settings={},\n    tools=None,\n    system_instruction=None,\n)}"
     ]
    }
   ],
   "source": [
    "from crewai_tools import FileReadTool, ScrapeWebsiteTool, MDXSearchTool, SerperDevTool\n",
    "\n",
    "search_tool = SerperDevTool()\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "read_resume = FileReadTool(file_path=\"./fake_resume.md\")\n",
    "semantic_search_resume = MDXSearchTool(\n",
    "    config=dict(\n",
    "        llm=dict(GoogleGenerativeAI(model=\"models/gemini-pro\", google_api_key=api_key)),\n",
    "        embedder=dict(\n",
    "            provider=\"google\",\n",
    "            config=dict(model=\"models/embedding-001\", task_type=\"retrieval_document\"),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uncomment and run the cell below if you wish to view `fake_resume.md` in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Markdown, display\n",
    "# display(Markdown(\"./fake_resume.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 303
   },
   "outputs": [],
   "source": [
    "# Agent 1: Researcher\n",
    "researcher = Agent(\n",
    "    role=\"Tech Job Researcher\",\n",
    "    goal=\"Make sure to do amazing analysis on \"\n",
    "         \"job posting to help job applicants\",\n",
    "    tools = [scrape_tool, search_tool],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"As a Job Researcher, your prowess in \"\n",
    "        \"navigating and extracting critical \"\n",
    "        \"information from job postings is unmatched.\"\n",
    "        \"Your skills help pinpoint the necessary \"\n",
    "        \"qualifications and skills sought \"\n",
    "        \"by employers, forming the foundation for \"\n",
    "        \"effective application tailoring.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 286
   },
   "outputs": [],
   "source": [
    "# Agent 2: Profiler\n",
    "profiler = Agent(\n",
    "    role=\"Personal Profiler for Engineers\",\n",
    "    goal=\"Do increditble research on job applicants \"\n",
    "         \"to help them stand out in the job market\",\n",
    "    tools = [scrape_tool, search_tool,\n",
    "             read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"Equipped with analytical prowess, you dissect \"\n",
    "        \"and synthesize information \"\n",
    "        \"from diverse sources to craft comprehensive \"\n",
    "        \"personal and professional profiles, laying the \"\n",
    "        \"groundwork for personalized resume enhancements.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 269
   },
   "outputs": [],
   "source": [
    "# Agent 3: Resume Strategist\n",
    "resume_strategist = Agent(\n",
    "    role=\"Resume Strategist for Engineers\",\n",
    "    goal=\"Find all the best ways to make a \"\n",
    "         \"resume stand out in the job market.\",\n",
    "    tools = [scrape_tool, search_tool,\n",
    "             read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"With a strategic mind and an eye for detail, you \"\n",
    "        \"excel at refining resumes to highlight the most \"\n",
    "        \"relevant skills and experiences, ensuring they \"\n",
    "        \"resonate perfectly with the job's requirements.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 286
   },
   "outputs": [],
   "source": [
    "# Agent 4: Interview Preparer\n",
    "interview_preparer = Agent(\n",
    "    role=\"Engineering Interview Preparer\",\n",
    "    goal=\"Create interview questions and talking points \"\n",
    "         \"based on the resume and job requirements\",\n",
    "    tools = [scrape_tool, search_tool,\n",
    "             read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"Your role is crucial in anticipating the dynamics of \"\n",
    "        \"interviews. With your ability to formulate key questions \"\n",
    "        \"and talking points, you prepare candidates for success, \"\n",
    "        \"ensuring they can confidently address all aspects of the \"\n",
    "        \"job they are applying for.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 269
   },
   "outputs": [],
   "source": [
    "# Task for Researcher Agent: Extract Job Requirements\n",
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the job posting URL provided ({job_posting_url}) \"\n",
    "        \"to extract key skills, experiences, and qualifications \"\n",
    "        \"required. Use the tools to gather content and identify \"\n",
    "        \"and categorize the requirements.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A structured list of job requirements, including necessary \"\n",
    "        \"skills, qualifications, and experiences.\"\n",
    "    ),\n",
    "    agent=researcher,\n",
    "    async_execution=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 286
   },
   "outputs": [],
   "source": [
    "# Task for Profiler Agent: Compile Comprehensive Profile\n",
    "profile_task = Task(\n",
    "    description=(\n",
    "        \"Compile a detailed personal and professional profile \"\n",
    "        \"using the GitHub ({github_url}) URLs, and personal write-up \"\n",
    "        \"({personal_writeup}). Utilize tools to extract and \"\n",
    "        \"synthesize information from these sources.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A comprehensive profile document that includes skills, \"\n",
    "        \"project experiences, contributions, interests, and \"\n",
    "        \"communication style.\"\n",
    "    ),\n",
    "    agent=profiler,\n",
    "    async_execution=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can pass a list of tasks as `context` to a task.\n",
    "- The task then takes into account the output of those tasks in its execution.\n",
    "- The task will not run until it has the output(s) from those tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 370
   },
   "outputs": [],
   "source": [
    "# Task for Resume Strategist Agent: Align Resume with Job Requirements\n",
    "resume_strategy_task = Task(\n",
    "    description=(\n",
    "        \"Using the profile and job requirements obtained from \"\n",
    "        \"previous tasks, tailor the resume to highlight the most \"\n",
    "        \"relevant areas. Employ tools to adjust and enhance the \"\n",
    "        \"resume content. Make sure this is the best resume even but \"\n",
    "        \"don't make up any information. Update every section, \"\n",
    "        \"inlcuding the initial summary, work experience, skills, \"\n",
    "        \"and education. All to better reflrect the candidates \"\n",
    "        \"abilities and how it matches the job posting.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"An updated resume that effectively highlights the candidate's \"\n",
    "        \"qualifications and experiences relevant to the job.\"\n",
    "    ),\n",
    "    output_file=\"tailored_resume.md\",\n",
    "    context=[research_task, profile_task],\n",
    "    agent=resume_strategist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "# Task for Interview Preparer Agent: Develop Interview Materials\n",
    "interview_preparation_task = Task(\n",
    "    description=(\n",
    "        \"Create a set of potential interview questions and talking \"\n",
    "        \"points based on the tailored resume and job requirements. \"\n",
    "        \"Utilize tools to generate relevant questions and discussion \"\n",
    "        \"points. Make sure to use these question and talking points to \"\n",
    "        \"help the candiadte highlight the main points of the resume \"\n",
    "        \"and how it matches the job posting.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A document containing key questions and talking points \"\n",
    "        \"that the candidate should prepare for the initial interview.\"\n",
    "    ),\n",
    "    output_file=\"interview_materials.md\",\n",
    "    context=[research_task, profile_task, resume_strategy_task],\n",
    "    agent=interview_preparer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 235
   },
   "outputs": [],
   "source": [
    "job_application_crew = Crew(\n",
    "    agents=[researcher,\n",
    "            profiler,\n",
    "            resume_strategist,\n",
    "            interview_preparer],\n",
    "\n",
    "    tasks=[research_task,\n",
    "           profile_task,\n",
    "           resume_strategy_task,\n",
    "           interview_preparation_task],\n",
    "\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Crew\n",
    "\n",
    "- Set the inputs for the execution of the crew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "job_application_inputs = {\n",
    "    'job_posting_url': 'https://jobs.lever.co/AIFund/6c82e23e-d954-4dd8-a734-c0c2c5ee00f1?lever-origin=applied&lever-source%5B%5D=AI+Fund',\n",
    "    'github_url': 'https://github.com/joaomdmoura',\n",
    "    'personal_writeup': \"\"\"Noah is an accomplished Software\n",
    "    Engineering Leader with 18 years of experience, specializing in\n",
    "    managing remote and in-office teams, and expert in multiple\n",
    "    programming languages and frameworks. He holds an MBA and a strong\n",
    "    background in AI and data science. Noah has successfully led\n",
    "    major tech initiatives and startups, proving his ability to drive\n",
    "    innovation and growth in the tech industry. Ideal for leadership\n",
    "    roles that require a strategic and innovative approach.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "### this execution will take a few minutes to run\n",
    "result = job_application_crew.kickoff(inputs=job_application_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dislplay the generated `tailored_resume.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"./tailored_resume.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dislplay the generated `interview_materials.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"./interview_materials.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONGRATULATIONS!!!\n",
    "\n",
    "## Share your accomplishment!\n",
    "- Once you finish watching all the videos, you will see the \"In progress\" image on the bottom left turn into \"Accomplished\".\n",
    "- Click on \"Accomplished\" to view the course completion page with your name on it.\n",
    "- Take a screenshot and share on LinkedIn, X (Twitter), or Facebook.  \n",
    "- **Tag @Joāo (Joe) Moura, @crewAI, and @DeepLearning.AI, (and a few of your friends if you'd like them to try out the course)**\n",
    "- **Joāo and DeepLearning.AI will \"like\"/reshare/comment on your post!**\n",
    "\n",
    "## Get a completion badge that you can add to your LinkedIn profile!\n",
    "- Go to [learn.crewai.com](https://learn.crewai.com).\n",
    "- Upload your screenshot of your course completion page.\n",
    "- You'll get a badge from CrewAI that you can share!\n",
    "\n",
    "(Joāo will also talk about this in the last video of the course.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
